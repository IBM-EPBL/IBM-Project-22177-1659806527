{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Build CNN Model for Classification Of Flowers**"
      ],
      "metadata": {
        "id": "lKjLc1DW5nSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#TEAM ID : PNT2022TMID04039"
      ],
      "metadata": {
        "id": "chDjOEyp5zBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from os import getcwd\n",
        "from os import listdir\n",
        "import cv2\n",
        "from keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense\n",
        "from keras.models import Model, load_model\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "import imutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "STmuToZ9Kdgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Download the dataset**"
      ],
      "metadata": {
        "id": "YldCaznzFuIb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMUHWpAhFlKZ",
        "outputId": "6d1ad99d-43f1-41b1-ea67-a606c390e2d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"/content/drive/MyDrive/Flowers-Dataset (assignment 3).zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()"
      ],
      "metadata": {
        "id": "ano1CYzWJhPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Number of Images in each class"
      ],
      "metadata": {
        "id": "lL2lKAy3ZbLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(os.listdir('/content/flowers/daisy')))\n",
        "print(len(os.listdir('/content/flowers/dandelion')))\n",
        "print(len(os.listdir('/content/flowers/rose')))\n",
        "print(len(os.listdir('/content/flowers/sunflower')))\n",
        "print(len(os.listdir('/content/flowers/tulip')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNKVX5ueJnyE",
        "outputId": "1a025fda-6cb7-4405-89d0-8b61a487e5d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "764\n",
            "1052\n",
            "784\n",
            "733\n",
            "984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2.Image Augumentation**"
      ],
      "metadata": {
        "id": "aUOuTESoMegI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAINING_DIR = \"/content/accdetection/training\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "train_generator = train_datagen.flow_from_directory(TRAINING_DIR,\n",
        "                                                    batch_size=100,\n",
        "                                                    class_mode='binary',\n",
        "                                                    target_size=(150, 150))\n",
        "\n",
        "\n",
        "VALIDATION_DIR = \"/content/accdetection/testing\"\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
        "validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,\n",
        "                                                              batch_size=100,\n",
        "                                                              class_mode='binary',\n",
        "                                                              target_size=(150, 150))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nS-M681eKYsJ",
        "outputId": "803048e8-15e2-48c7-9a44-93aadd342e54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 4292 images belonging to 5 classes.\n",
            "Found 1243 images belonging to 5 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3.Create model**"
      ],
      "metadata": {
        "id": "Zo2TJMq7NPHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Convolution2D,MaxPooling2D,Flatten,Dense"
      ],
      "metadata": {
        "id": "Q5ebc2qSLmLa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4.Add layers**"
      ],
      "metadata": {
        "id": "r0SOtIPTLnCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(100, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "    tf.keras.layers.Conv2D(100, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    \n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(50, activation='relu'),\n",
        "    tf.keras.layers.Dense(50, activation='softmax')\n",
        "])\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XFYHiAXNFOI",
        "outputId": "7bc75f0b-9fab-473a-a610-91f8daeefcfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 148, 148, 100)     2800      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 74, 74, 100)      0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 72, 72, 100)       90100     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 36, 36, 100)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 129600)            0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 129600)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 50)                6480050   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 50)                2550      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 6,575,500\n",
            "Trainable params: 6,575,500\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5.Compile the model**"
      ],
      "metadata": {
        "id": "Mg9Qet-SLS1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "model.compile(optimizer=opt,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['acc'])"
      ],
      "metadata": {
        "id": "ZMLBb5X7L4Qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6.Fit the model**"
      ],
      "metadata": {
        "id": "Am0hXC1XL5Jz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "            train_generator,\n",
        "            validation_data=validation_generator,\n",
        "            epochs=10,\n",
        "            verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sg_fxHovTe5n",
        "outputId": "483235d7-48c3-4b02-c2a2-221724ee3a6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "43/43 [==============================] - 439s 10s/step - loss: 1.5641 - acc: 0.3663 - val_loss: 1.1328 - val_acc: 0.5294\n",
            "Epoch 2/10\n",
            "43/43 [==============================] - 435s 10s/step - loss: 1.1847 - acc: 0.5156 - val_loss: 1.0994 - val_acc: 0.5414\n",
            "Epoch 3/10\n",
            "43/43 [==============================] - 431s 10s/step - loss: 1.1077 - acc: 0.5571 - val_loss: 0.9780 - val_acc: 0.6227\n",
            "Epoch 4/10\n",
            "43/43 [==============================] - 428s 10s/step - loss: 1.0248 - acc: 0.5939 - val_loss: 0.9686 - val_acc: 0.6275\n",
            "Epoch 5/10\n",
            "43/43 [==============================] - 436s 10s/step - loss: 0.9705 - acc: 0.6233 - val_loss: 0.9084 - val_acc: 0.6492\n",
            "Epoch 6/10\n",
            "43/43 [==============================] - 432s 10s/step - loss: 0.9435 - acc: 0.6323 - val_loss: 0.9555 - val_acc: 0.6372\n",
            "Epoch 7/10\n",
            "43/43 [==============================] - 425s 10s/step - loss: 0.9300 - acc: 0.6398 - val_loss: 0.9788 - val_acc: 0.6122\n",
            "Epoch 8/10\n",
            "43/43 [==============================] - 433s 10s/step - loss: 0.9085 - acc: 0.6470 - val_loss: 0.8271 - val_acc: 0.6766\n",
            "Epoch 9/10\n",
            "43/43 [==============================] - 433s 10s/step - loss: 0.8956 - acc: 0.6573 - val_loss: 0.8002 - val_acc: 0.6718\n",
            "Epoch 10/10\n",
            "43/43 [==============================] - 434s 10s/step - loss: 0.8556 - acc: 0.6759 - val_loss: 0.8035 - val_acc: 0.7056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7.Save the model**"
      ],
      "metadata": {
        "id": "KTVrTD4GMPSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('Flower Classification.h5')"
      ],
      "metadata": {
        "id": "INGZfaMGMFBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8.Test the model**"
      ],
      "metadata": {
        "id": "Lt2oYA6CMYUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "img = image.load_img('/content/accdetection/testing/sunflower img/18876985840_7531dc8e6a.jpg',target_size=(150,150))\n",
        "s = image.img_to_array(img)\n",
        "s = np.expand_dims(s,axis=0)\n",
        "s"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxmBtmopzaL2",
        "outputId": "2267af33-becf-46f4-c3b9-3b834f341bf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 28.,  55.,  10.],\n",
              "         [ 20.,  33.,  13.],\n",
              "         [ 18.,  26.,  13.],\n",
              "         ...,\n",
              "         [ 63., 106.,  35.],\n",
              "         [ 62., 107.,  26.],\n",
              "         [ 46.,  87.,  21.]],\n",
              "\n",
              "        [[ 31.,  59.,  11.],\n",
              "         [ 22.,  36.,  13.],\n",
              "         [ 16.,  24.,   9.],\n",
              "         ...,\n",
              "         [ 61., 103.,  39.],\n",
              "         [ 61., 105.,  26.],\n",
              "         [ 49.,  90.,  22.]],\n",
              "\n",
              "        [[ 31.,  61.,  11.],\n",
              "         [ 22.,  38.,  12.],\n",
              "         [ 16.,  27.,  10.],\n",
              "         ...,\n",
              "         [ 58., 100.,  36.],\n",
              "         [ 58., 102.,  25.],\n",
              "         [ 48.,  91.,  20.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 58.,  87.,  33.],\n",
              "         [ 50.,  88.,  31.],\n",
              "         [ 42.,  81.,  28.],\n",
              "         ...,\n",
              "         [ 40.,  78.,  27.],\n",
              "         [ 40.,  78.,  29.],\n",
              "         [ 32.,  63.,  19.]],\n",
              "\n",
              "        [[ 53.,  79.,  32.],\n",
              "         [ 52.,  85.,  28.],\n",
              "         [ 45.,  80.,  24.],\n",
              "         ...,\n",
              "         [ 41.,  79.,  28.],\n",
              "         [ 38.,  76.,  27.],\n",
              "         [ 31.,  64.,  17.]],\n",
              "\n",
              "        [[ 51.,  77.,  29.],\n",
              "         [ 50.,  83.,  26.],\n",
              "         [ 48.,  83.,  27.],\n",
              "         ...,\n",
              "         [ 41.,  79.,  28.],\n",
              "         [ 37.,  75.,  26.],\n",
              "         [ 30.,  67.,  13.]]]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gg7Ux1s4C7ey",
        "outputId": "8ab72b84-0228-4645-8eaa-67843e19c25e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = ['daisy','dandelion','rose','sunflower','tulip']\n",
        "pred = np.argmax(model.predict(s))\n",
        "output[pred]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "K3SDpLiiDN8E",
        "outputId": "62b9b430-a061-4eba-cf7f-d38b84b330d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sunflower'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = image.load_img('/content/accdetection/testing/sunflower img/18876985840_7531dc8e6a.jpg',target_size=(150,150))\n",
        "s = image.img_to_array(img)\n",
        "s = np.expand_dims(s,axis=0)\n",
        "pred = np.argmax(model.predict(s))\n",
        "output[pred]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "_s5B6o7DDjEI",
        "outputId": "c92b13fc-3936-4c5c-bf92-ae329b13cbd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sunflower'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = image.load_img('/content/accdetection/testing/daisy img/12601254324_3cb62c254a_m.jpg',target_size=(150,150))\n",
        "s = image.img_to_array(img)\n",
        "s = np.expand_dims(s,axis=0)\n",
        "pred = np.argmax(model.predict(s))\n",
        "output[pred]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "uYiGQAdXD2Bh",
        "outputId": "e74eefe7-5826-4420-d8bc-efe5a17f8403"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'daisy'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = image.load_img('/content/accdetection/testing/tulip img/14046760909_0c73e84a1f_n.jpg',target_size=(150,150))\n",
        "s = image.img_to_array(img)\n",
        "s = np.expand_dims(s,axis=0)\n",
        "pred = np.argmax(model.predict(s))\n",
        "output[pred]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "NBqx5EMREQ6h",
        "outputId": "8779af08-37a5-4888-e386-f4019a1daee4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'tulip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img = image.load_img('/content/accdetection/testing/rose img/12395698413_c0388278f7.jpg',target_size=(150,150))\n",
        "s = image.img_to_array(img)\n",
        "s = np.expand_dims(s,axis=0)\n",
        "pred = np.argmax(model.predict(s))\n",
        "output[pred]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "cjBaHjutEjUJ",
        "outputId": "ee1cb45b-2035-4f17-f0b3-48c3f41165b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'rose'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VB6Jeu8e0w3_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}